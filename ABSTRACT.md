**CosegPP** is a subset of a comprehensive dataset acquired from the LemnaTec Scanalyzer system at the University of Nebraska-Lincoln, a 3D plant phenotyping system. This extensive dataset encompasses a wide range of plant species, imaging techniques, time points, and experimental samples. The LemnaTec system comprises four imaging chambers, each equipped with distinct camera types designed to capture various perspectives, including visible light, infrared, fluorescent, and near-infrared. The flexibility of chamber lifters allows for versatile imaging, resulting in a diverse and rich dataset.

Cosegmentation, an emerging technique in computer vision, focuses on the simultaneous segmentation of objects from their backgrounds in multiple images. Traditional plant phenotyping heavily relies on threshold-based segmentation methods, whereas machine learning approaches often require specific features extracted from training datasets. In the case of CosegPP, this dataset includes images of Buckwheat and Sunflower plants under different experimental conditions, harnessing high-throughput phenotyping technologies.

In the original research paper, the authors assess the CosegPP dataset using various cosegmentation algorithms alongside a conventional plant phenotyping method. Their goal is to establish a benchmark for segmentation accuracy and to facilitate ongoing improvements in segmentation methodologies. This dataset plays a pivotal role in advancing the field of plant phenotyping.

CosegPP has *buckwheat-C-1*, *buckwheat D-1*, *sunflower-C-1*, and *sunflower-D-1* as datasets. The dataset name starts with the name of the plant. C indicates control, D indicates drought, and 1 represents the plant ID number. Each dataset has 12 groups that are labeled with combinations of the three ***modality*** (fluorescence, IR, Vis), perspectives (SV), and degree ***angle*** (0, 72, 144, 216) the photo was taken. Some example groups are: Fluo_SV_0, IR_SV_72, and Vis_SV_144. Each group has a range of PNG images named after timestamps.

Ground truth images were generated using Photoshop2020's Action feature, which involved Quick Selection, Masking, Mode Conversion, Thresholding, and Inversion steps. Following the creation of a binary mask, two computer scientists assessed and refined each mask for quality by adding or removing pixels. This process resulted in a binary mask for each timestamp, modality, and perspective. Previous studies have also employed Photoshop, either fully or partially, for manual techniques in producing binary masks.
